---
hide:
  #- navigation # 显示右
  #- toc #显示左
  - footer
  - feedback
comments: true
--- 

# Chapter 15 : External Sorting

## Introduction

> 我们先前所学的所有排序算法，都是利用主存 (Main Memory) 运行的内部排序，在数据量不大（即主存能够容纳所有待排序数据）可以顺利地完成排序工作。

然而，一旦数据量很大，主存无法容下所有待排序数据时，就需要用到**外部排序**(External Sorting) 算法。所谓“外部”，即用到磁盘的空间。我们在[计算机组成](https://brucejqs.github.io/MyNotebook/blog/Computer%20Science/Computer%20Organization/Chapter%205/#memory-hierarchy-introduction)中也学过，磁盘相比主存空间更大，但访问速度更慢。举个例子：若要访问数组的某个元素 `a[i]`，它们所需的时间分别为：

- 主存：$O(1)$（用索引寻找，随机访问）
- 磁盘：找到元素所在的迹 (Track) -> 找到对应的区 (Sector)（磁盘存储信息的最小单位）-> 找到元素 `a[i]` 并传输数据
    - 这一过程的快慢还取决于设备的性能
    - 要想提升访问速度，我们应尽可能让磁盘读写头沿着一个方向移动，以避免磁盘频繁的旋转

我们将归并排序（MergeSort）作为外部排序的算法。为了简化后续的分析过程，我们假定：

- 存储数据集的容器称为**磁带**（Tape），里面的元素只能按顺序访问（这符合磁盘读写头的特性）
- 至少需要使用 3 个磁带（2 个子序列合并成 1 个更大的序列）

!!! example "Example"

	=== "Question"
	
		假设主存一次最多只能处理 $M=3$ 条记录，请通过外部排序算法（归并排序）来实现对以下序列的排序：
	
		![](../../../assets/Pasted%20image%2020241224101750.png)
	
	=== "Answer"
	
		我们称在主存中排好序的一组数据称为 **Run**，用趟（Pass）来表示归并排序合并两个子序列，形成一个更大子序列的过程
		
		=== "Pass 1"
		
			- 由于一次最多只能对 3 条记录进行排序，所以将原序列分为若干组，每组有 3 条记录，一组组地进行排序（排序算法任意）
			- 由于归并排序至少需要 3 条磁带，因此不能将排好序的组放入同一个磁带内，要分开来放，这里规定相邻的两个组放在不同的磁带里
			
			![](../../../assets/Pasted%20image%2020241224102145.png)
		
		=== "Pass 2"
		
			将两个 Tape 进行归并排序，放在两个不同的磁带里（可以使用原有空闲的磁带）
			
			![](../../../assets/Pasted%20image%2020241224102306.png)
		
		=== "Pass 3"
		
			进一步归并排序，最后就可以排序完成（最后一步略）
			
			![](../../../assets/Pasted%20image%2020241224102359.png)
		
		因此我们一共用了 $1+3=4$ 趟

- 一般情况下，若要对 $N$ 条记录进行外部排序，且主存最多对 $M$ 条记录进行排序，需要的趟数为 $1+\lceil\log_{2}\frac{N}{M}\rceil$

在设计外部排序的时候，我们会关心以下问题：

- **寻找**时间——$O(\text{Number of Passes})$
- **读 / 写**一个记录**块**（一组记录集）的时间
- 对 $M$ 条记录进行**内部排序**的时间
- 从输入缓存（就是磁带）**合并** $N$ 条记录到输出缓存所需的时间

要实现外部排序，需要解决以下问题：

- 减少趟的数量
- 合并 Run（一组排好序的记录）
- 用并行算法处理缓存
    - 注意：计算机可以并行处理 I/O 和 CPU
- 生成 Run
***
## Pass Reduction

### k-Way Merge

根据前面关于趟数的结论，要想减少趟数，一种很自然的想法便是增大对数函数的底数 $k$（原来 $k=2$），也就是增加子序列的个数，以 $k=3$ 为例：

!!! example "k-Way Merge"

	和上面的例子需要排序的数据一样：
	
	=== "Pass 1"
	
		![](../../../assets/Pasted%20image%2020241224103500.png)
	
	=== "Pass 2"
	
		![](../../../assets/Pasted%20image%2020241224103559.png)
		
		需要注意的是，由于需要同时比较三个数据，因此这里用到了**最小堆**，便于随时取出最小的数据，并加入下一个待排序的数据。
		
		本例中，第 3 个子序列为空，但为了一般性的解释，我们还是为第 3 个子序列预留了一个磁带。

有了以上的优化，我们的趟数就能降到 $1+\lceil\log_{k}\frac{N}{M}\rceil$，但是所需的磁带数升至 $2k$ 个，这样的开销有点难以接受
***
### Polyphase Merge

我们希望在降低趟数的同时能够尽可能避免磁带数的提升，因此尝试一下在保持子序列个数不变的情况下减少所需磁带数，下面以 $k=2$，磁带数 $=3$ 为例进行分析：

!!! example "Example"

	如果原序列已经排成了 34 个 run：
	
	![](../../../assets/Pasted%20image%2020241224105736.png)
	
	我们将原来的 34 个 run 均分为包含 17 个 run 的两个子序列，然后对它们进行合并，形成一个 17 个 run 的完整序列，此时每个 run 会包含更多排好序的记录。
	
	![](../../../assets/Pasted%20image%2020241224105910.png)
	
	- 由于这么一趟下来后只有一条磁带里包含记录，为了继续合并，还是需要将所有的 run 一分为二。因此在进入下一趟操作前，需要将包含记录的磁带的一半的 run 拷贝到另一个空磁带上。
	- 但是对于磁盘来说，拷贝所需成本有些大，所以如果像这样简单地减少磁带数量，可能会带来更大的成本损耗（像这个例子就需要 6 个 Pass，5 次拷贝）

这里给出一种更聪明的算法——**多相合并**（Polymerge Sort），它的改进之处在于：在起始步的时候，对原序列进行**不均等的分割**，形成大小不一的子序列。这样可以确保在每一趟结束后，（除了最后阶段外）始终会有多个包含记录的子序列，因此无需额外高昂的拷贝操作。照着上面的例子来看：

!!! example "Polymerge Sort"

	=== "Pass 1"
	
		我们将原序列（34 runs）划分为大小不一的两个子序列（21 runs + 13 runs）
		
		![](../../../assets/Pasted%20image%2020241224110041.png)
		
		合并两个子序列后，还会剩下两个子序列：
		
		- 其中一个是刚合并好的结果序列（13 runs）
		- 另一个是剩下未进行合并的子序列（8 runs）
		
		![](../../../assets/Pasted%20image%2020241224110353.png)
	
	=== "Pass 2"
	
		按 Pass 1 类似的方法进行合并，变成合并后的 8 runs 子序列和剩下的 5 runs 子序列：
		
		![](../../../assets/Pasted%20image%2020241224110440.png)
	
	=== "Pass 3"
	
		按 Pass 1 类似的方法进行合并，变成合并后的 5 runs 子序列和剩下的 3 runs 子序列：
		
		![](../../../assets/Pasted%20image%2020241224110556.png)
	
	=== "Pass 4"
	
		按 Pass 1 类似的方法进行合并，变成合并后的 3 runs 子序列和剩下的 2 runs 子序列：
		
		![](../../../assets/Pasted%20image%2020241224110650.png)
	
	=== "Pass 5"
	
		按 Pass 1 类似的方法进行合并，变成合并后的 2 runs 子序列和剩下的 1 run 子序列：
		
		![](../../../assets/Pasted%20image%2020241224110756.png)
	
	=== "Pass 6"
	
		按 Pass 1 类似的方法进行合并，变成合并后的 1 run 子序列和剩下的 1 run 子序列：
		
		![](../../../assets/Pasted%20image%2020241224110840.png)
	
	=== "Pass 7"
	
		最后合并完成：
		
		![](../../../assets/Pasted%20image%2020241224110927.png)
	
	一共需要 7 个 Pass

当然，这个方法非常吃分割的方法，如果我们将 34 个分割成 22 和 12，就会出现下面的情况：

![](../../../assets/Pasted%20image%2020241224111201.png)

需要 10 个 Run，还外带一次拷贝，就非常难蚌，那么怎么分才能达到上例呈现的效果呢？或许有人根据上面的例子能看出猫腻了，`13,8,5,3,2...` ，这难道不是 Fibonacci 数列嘛？下面给出结论：

- 对于两路归并排序，如果序列中 Run 的数量是一个**斐波那契数** $F_N$​，那么最好的分割情况是将它分成包含 $F_{N−1}$ 个 run 和 $F_{N−2}$ 个 run 的子序列。
    - 如果初始 run 的数量不是一个斐波那契数的话也没有问题，只需找到离该数最接近的斐波那契数，然后按照这个斐波那契数的递推式将其分成两个子序列（注意其中一个子序列可能也不是斐波那契数）
- 对于 $k$ 路归并排序，$F_N(k)=F_{N−1}(k)+⋯+F{N−k}(k)$，其中 $F_N(k)=0(0\leq N\leq k−2),F_{k−1}(k)=1$
    - 因此，对于 $k$ 路归并排序，只需要 $k+1$ 个磁带就够了
    - 一般情况下，可能很难做到将 Run 的数量划分为多个斐波那契数，但我们应确保有尽可能多的斐波那契数
***
### Replacement Selection

> FDS Bonus 第二道题就是这个算法（回过头才发现原来第一道是计组学的 LRU hhh）

除了提升 $k$ 值外，我们还可以尝试通过生成更长的 Run 来减小趟数，这里我们用到一个称为**置换选择**（Replacement Selection）的算法来实现这一目标

