---
hide:
  #- navigation # 显示右
  #- toc #显示左
  - footer
  - feedback
comments: true
--- 

# Chapter 03 : Instruction-Level Parallelism (ILP)

!!! abstract "Abstract"

	 在计组我们学习的流水线 CPU 仅仅只是考虑了整数指令的操作，且默认每次操作需要一个时钟周期，那对于浮点数的操作呢？浮点数操作所需要的时间远比整数操作时间大，那么当我们添加浮点数操作时，是该使用一个更慢的时钟？还是去各种优化浮点数模块呢？

## Introduction

### Multicycle FP Operation

- 浮点数流水线
	- 允许对于一次操作更长的时延，例如，对于 EXE 模块用大于 1 个时钟周期的时间来完成操作
	- 在整数流水线上的两个改变：
		- 重复使用 EXE 模块
		- 使用多样的浮点数函数单元（比如浮点数加法器，浮点数除法）

![](../../../assets/Pasted%20image%2020250406222844.png)

可以看到，EX 模块并没有使用流水线的方式执行：

- 直到前一条指令离开 EX 模块，不能发起（Issue）使用该功能单元的其他指令
- 如果有一条指令没法前进到 EX 模块，在这条指令之后整个流水线都会停顿
***
### Latency & Ini/Repeat Interval

- 时延（Latency）：产生结果的指令和使用结果的指令之间需要的时钟周期数
- 初始化/重复间隔（Initiation/Repeat Interval）：发出给定类型的两个操作之间必须经过的时钟周期数

各个功能单元的时延和初始化/重复间隔如下：

![](../../../assets/Pasted%20image%2020250406224119.png)

一些解释：

- 对于我们学习过的整数 ALU，因为有 Forwarding 的存在，所以时延为 0

![](../../../assets/Pasted%20image%2020250406225546.png)

- 对于数据存储器来说，即 Load-Use Hazard 的情况，必须加一个停顿周期，所以时延为 1

![](../../../assets/Pasted%20image%2020250406225658.png)

- 当连续两个指令都是 Load 指令时，第二个 Load 指令必须等第一个 Load 指令完成才能执行，所以重复间隔为 1

![](../../../assets/Pasted%20image%2020250406225831.png)

特别需要注意的是：流水线的时延永远比执行模块到产生结果的时钟周期数要小 1 个时钟周期

![](../../../assets/Pasted%20image%2020250406230021.png)
***
### Structural Hazard

在加入浮点数操作之后，就会造成一个新的问题，因为不同的浮点数操作并不完全是流水线式的，且需要的时钟周期也不同，这会导致有可能会出现在同一个时钟周期出现不止一次的寄存器写操作，这就造成了结构冒险（Structural Hazard）

![](../../../assets/Pasted%20image%2020250406230427.png)

- 解决方法——联锁检测（Interlock Detection）：
	- 方法一：在译码阶段就记录写端口的使用情况，并在指令发起之前停顿一个周期
		- 移位寄存器记录何时已发起的指令将使用寄存器堆
		- 如果在译码阶段有指令需要使用寄存器堆，则停顿一个周期
	- 方法二：当指令要进入 MEM/WB 模块时，停顿这个指令
		- 可以停顿正在发起或者已经发起的指令
		- 给最长时延单元最高的优先级
		- 更复杂情况是，在两个地方都需要停顿
***
### WAW Hazard

不仅仅是结构冒险，由于指令并不是按照指令的既定顺序到达 WB 模块了，所以就会出现 WAW 冒险（Write After Write Hazard），即两个指令都要写入同一个寄存器，但是第二条指令在第一条指令之前到达了 WB 模块

![](../../../assets/Pasted%20image%2020250406231750.png)

- 解决方法：
	- 方法一：延后 fld 指令的发起
	- 方法二：fadd.d 的零写入控制
***
### RAW Hazard

RAW 冒险（Read After Write Hazard）就是和我们的 Load-Use 冒险同理，只是因为加入了浮点数操作，所以会造成更多更复杂的情况

![](../../../assets/Pasted%20image%2020250406233128.png)

![](../../../assets/Pasted%20image%2020250406233152.png)
***
### Hazard: Exceptions

由于不同浮点数操作需要的时钟周期不同，所以一系列指令的结束顺序很可能和发起顺序不同，这就会造成异常（Exception）
***
#### Hazard Detection in ID

- 检查结构冒险
	- 确保当寄存器写端口被需要时是可用的
	- 直到需要的功能单元不忙碌时再做（仅限除法）
- 检查 RAW 数据冒险
	- 直到源寄存器在需要时可用再做——当它们不是已发起指令的待处理目标时
- 检查 WAW 冒险
	- 检查任何 A1-A4，D，M1-M7 中的指令是否有和当前指令相同的目的寄存器
	- 如果有，则停顿当前指令在 ID 阶段的发起
***
#### Forwarding

因为数据冒险更为多样复杂了，Forwarding 的情况也变得更多了（EX/MEM, A4/MEM, M7/MEM, D/MEM, MEM/WB）
***
#### Out-of-Order Completion

指令结束的顺序不同的解决方法有：

- 直接忽略
- 将指令的结果写入缓冲器中，直到其他比当前指令先发起的指令完成
- 记录流水线当中执行的指令和它们的 PC
- 只有确认所有之前的指令完成时不会造成异常，才发起指令
***
## ILP Exploitation

> ILP 的实现重点是寻找依赖关系（Dependence），只要两个指令没有互相依赖就可以进行并行

有两类利用指令集并行的方法：

- 基于**硬件**的**动态**并行
- 基于软件（**编译器**）的**静态**（编译时）并行：仅限于领域特定的环境或者结构良好的且具备较大程度的数据级并行的科学应用中

如果两条指令是并行的话，意味着它们能够在同一个流水线中同时执行，且不会造成任何停顿（假设流水线有足够多的资源，不会造成结构冒险问题）

在设计 ILP 时，我们必须要考虑指令之间是否存在**依赖关系**。依赖关系一般分为**数据依赖**（Data Dependence）、**名称依赖**（Name Dependence）和**控制依赖**（Control Dependence）三种类型
***
### Data Dependence

如果满足下列条件，那我们称指令 j 数据依赖于指令 i：

- 指令 i 的执行结果会被指令 j 用到
- 指令 j 数据依赖于指令 k，而指令 k 数据依赖于指令 i

第二个条件告诉我们：多条指令间可能存在一条依赖链，甚至这条链可以遍布于整个程序中

- 需要注意的是：单条指令间的依赖关系（比如 `add x1, x1, x1`）不视为存在依赖

!!! example "Example"

	考虑以下 RISC-V 代码：
	
	```asm
	Loop:
	    fld      f0, 0(x1)      // f0 = array element
	    fadd.d   f4, f0, f2     // add scalar in f2
	    fsd      f4, 0(x1)      // store result
	    addi     x1, x1, -8     // decrement pointer 8 bytes
	    bne      x1, x2, Loop   // branch x1 != x2
	```
	
	这段代码中的数据依赖包括：2-3 行的 `f0`、3-4 行的 `f4` 和 5-6 行的 `x1`

如果两条指令间存在数据依赖关系，则必须保留这两条指令的执行顺序，不得让它们同时执行，因为这可能蕴含着单个或多个数据冒险
***
### Name Dependence

当两条指令使用相同的寄存器或内存位置（称为**名称**（Name）），但这两条指令之间没有关于该名称的数据流时，我们认为发生了**名称依赖**（Name Dependences）。有以下两类名称依赖（假设指令 j 的程序顺序在指令 i 后面）：

- **反依赖**（Antidependence）：指令 j 向指令 i 读取的寄存器或内存位置上进行写操作
- **输出依赖**（Output Dependence）：当指令 i 和 j 向同一个寄存器或内存位置上进行写操作

正如定义所言，由于具有名称依赖的两条指令之间不存在数据流，所以这种依赖不是真正的依赖，也就是说这样的指令可以并行执行或重新排序，只要改变这些指令使用的名称（寄存器或内存位置），让指令间不冲突就行了

对于寄存器而言，这种重命名操作更加容易（称为**寄存器重命名**（Register Renaming）），可以用编译器或由硬件动态处理
***
### Data Hazards

当指令间存在名称或数据依赖时，如果这样的指令足够接近，能够被重叠执行的话，那么就可能会改变访问和依赖相关的操作数的顺序，此时冒险就发生了。为了避免冒险的发生，在并行时必须保留那些会影响到程序执行结果的**程序顺序**（Program Order），即按源程序顺序来执行指令的顺序

对于**数据冒险**（Data Hazard），我们根据指令的读写访问顺序，将其划分为以下几类（还是假设指令 j 的程序顺序在指令 i 的后面）：

- **RAW**（Read after Write）：j 尝试在 i 写入某个源操作数之前读取它，这样 j 就会得到旧的数据。这是最常见的一类冒险，且对应真正的**数据依赖**
- **WAW**（Write after Write）：j 尝试在 i 写入某个操作数之前向它写入，这样导致写操作的执行顺序错误，该操作数的最终结果是 i 写入的结果而非 j。该冒险对应**输出依赖**，且仅存在于允许在多个阶段写入数据的流水线，或者允许指令在前一条指令停顿时继续执行的情况下
- **WAR**（Write after Read）：j 尝试在 i 读取某个目的操作数之前先向它写入，这样 i 就会错误地得到了新的数据。该冒险对应**反依赖**，在大多数静态发射的流水线中不会发生
***
### Control Dependence

**控制依赖**（Control Dependence）决定了指令 i 关于分支指令的顺序。除了程序的第一个基本块外，所有指令都和某些分支之间存在控制依赖，并且这些控制依赖必须被保留下来，以保留程序顺序。考虑以下代码块：

```c
if p1 {
    S1;
}
if p2 {
    S2;
}
```

不难发现：`S1` 控制依赖于 `p1`，`S2` 控制依赖于 `p2` 而非 `p1`。

控制依赖带来以下约束：

- 关于某个分支控制依赖的指令不得被移动到分支之**前**，否则的话该指令就**不被**该分支所**控制**
- 不受某个分支控制依赖的指令不得被移动到分支之**后**，否则的话该指令就要被该分支所**控制**

事实上，我们不需要严格保留控制依赖，而只需要保留两个关键的性质：**异常行为**（Exception Behaviour）和**数据流**（Data Flow）

- 保留**异常行为**意味着任何对指令执行顺序作出的改动，不能改变程序如何产生异常的
	- 更松弛的版本是：对指令执行的重新排序不得导致程序中出现新的异常
- **数据流**是指令间产生结果或接受输入中的数据值的真实流动
	- 分支让数据流变得动态，因为它们让数据源可以来自很多地方。通过保留控制仪阿里，就能够阻止对数据流的非法变化
***
## Static Scheduling

### Pipeline Scheduling

流水线调度指的是编译器在编译时就重排指令的执行顺序，最后减少一些不必要的停顿

!!! example "Example"

	对于以下 C 代码：
	
	```c
	for (i = 999; i >= 0; i--)
	    x[i] += s;
	    ```
	
	将其转化为 RISC-V 代码，且没有做过任何调度的结果如下所示：
	
	```asm
	Loop:
	    fld     f0, 0(x1)
	    fadd.d  f4, f0, f2
	    fsd     f4, 0(x1)
	    addi    x1, x1, -8
	    bne     x1, x2, Loop
	```
	
	如果没有调度的话，执行一趟循环需要停顿 8 个时钟周期：
	
	![](../../../assets/Pasted%20image%2020250415141851.png)
	
	但如果我们将 `addi` 指令移到 `fld` 的下一条指令的位置上，就可以消除一个停顿：
	
	![](../../../assets/Pasted%20image%2020250415141926.png)
***
### Loop Unrolling

对于上面的例子，事实上真正对数组操作的指令只有三条（`fld`、`fadd.d`、`fsd`）；对于剩下的两个停顿，以及 `addi` 和 `bne` 指令，我们希望能够消除掉，因此我们有**循环展开**（Loop Unrolling）的方法，具体来说就是拷贝多份循环体，并调整循环终止相关的代码。此外，该方法还能提升调度，因为它消除了分支，所以能允许不同迭代下的指令被一起调度

!!! example "Example"

	对于上面的例子，使用循环展开，拷贝 4 份循环体。这里假设 `x1 - x2` 的值是 32 的倍数，这也意味着迭代次数为 4 的倍数
	
	在展开的时候，我们合并了 `addi` 指令，并删掉了不必要的重复的 `bne` 指令。结果如下所示：
	
	![](../../../assets/Pasted%20image%2020250415142259.png)
	
	如果没有调度的话，上述改变不会对性能带来多少提升（每趟循环 6.5 个时钟周期）；但是再加上调度的话，就能够显著提升性能了（每趟循环 3.5 个时钟周期），结果如下所示：
	
	![](../../../assets/Pasted%20image%2020250415142315.png)
***
## Dynamic Branch Prediction

在[计组](https://brucejqs.github.io/MyNotebook/blog/Computer%20Science/Computer%20Organization/Chapter%204/#control-hazards)当中我们介绍过简单的分支预测器（Predictors）；但对于更深层的流水线以及多发射处理器，我们需要更精确的分支预测，相对于计组中的简单的静态预测，动态预测更为精确，下面就介绍提高动态预测精度的高级技术
***
### Correlating Branch Predictors

我们可以通过观察**其他**分支的最近行为来提升预测的精度：

!!! example "Example"

	考虑以下具有多分支的代码：
	
	```c
	if (aa != 2)
	    aa = 0;
	if (bb != 2)
	    bb = 0;
	if (aa == bb) {
	    // ...
	}
	```
	
	对应的 RISC-V 代码为：
	
	```asm
	    addi x3, x1, -2
	    bnez x3, L1         // branch b1
	    add x1, x0, x0      // aa = 0
	L1:
		addi x3, x2, 02
		bnez x3, L2         // branch b2
		add x2, x0, x0      // bb = 0
	L2:
		sub x3, x1, x2      // x3 = aa - bb
		beqz x3, L3         // branch b3
	```

我们称能够利用其他分支的行为来预测的预测器为**相关预测器**（Correlating Predictors) 或**两级预测器**（Two-level Predictors）。相关预测器会添加和最近分支的行为相关的信息，来决定如何预测给定的分支。一个 $(m,n)$ 预测器能够预测最近 $m$ 个分支的行为，来选择 $2^m$ 个分支预测器，每个都是对应单个分支的 $n$ 位预测器。这类预测器能够在仅增加少量硬件的基础上，就能产生比 2 位预测器更高的预测率。相关预测器的结构大致如下所示：

![](../../../assets/Pasted%20image%2020250415155144.png)

$(m,n)$ 预测器的总位数为：

$$
\text{Total Bits} = 2^m \times n \times\text{Number of prediction entries selected by the branch address}
$$





